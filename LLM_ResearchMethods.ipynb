{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7/2EVSLO0fYr73nMCA38J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harishchandu12/LLM_ResearchMethods/blob/main/LLM_ResearchMethods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for data processing, visualization, text analysis, and machine learning\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Install required libraries for transformer models and latest scikit-learn\n",
        "!pip install transformers -q\n",
        "!pip install -U scikit-learn -q\n",
        "# Import PyTorch and model evaluation utilities\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
        "# Import necessary components from Hugging Face Transformers and PyTorch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "# Detect and assign the computing device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "# Import resampling method to handle class imbalance\n",
        "from sklearn.utils import resample"
      ],
      "metadata": {
        "id": "hnINsGi-lglt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh_6hbh-L83V",
        "outputId": "791d3916-c4ef-47e6-e593-ad47d7def7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Id  Clothing ID  Age                              Title  \\\n",
            "0  14746            0   26                                NaN   \n",
            "1  22742            1   50    Love this under-all cami tank ?   \n",
            "2  22743            1   36                       Staple tank!   \n",
            "3  22749            1   24        Love but also very annoying   \n",
            "4    876            2   28  Gorgeous top, straps way too long   \n",
            "\n",
            "                                         Review Text  Rating  Recommended IND  \\\n",
            "0                                                NaN       5                1   \n",
            "1  Originally i bought this in black and white. r...       5                1   \n",
            "2  Love this tank. material and fit are great. lo...       5                1   \n",
            "3  I love this tank, it is so comfortable but it ...       2                0   \n",
            "4  I just adore this top! it is so comfy and styl...       4                1   \n",
            "\n",
            "   Positive Feedback Count Division Name Department Name Class Name  \n",
            "0                        0       General         Jackets  Outerwear  \n",
            "1                        0     Initmates        Intimate   Layering  \n",
            "2                        0     Initmates        Intimate   Layering  \n",
            "3                        1     Initmates        Intimate   Layering  \n",
            "4                        0       General            Tops      Knits  \n"
          ]
        }
      ],
      "source": [
        "# Load the women's clothing e-commerce review dataset from the provided GitHub URL\n",
        "Clothesdata = 'https://raw.githubusercontent.com/Harishchandu12/LLM_ResearchMethods/refs/heads/main/Womens%20Clothing%20E-Commerce%20Reviews.csv'\n",
        "Clothesdata_df = pd.read_csv(Clothesdata)\n",
        "# Display the first five rows to preview the structure and content of the dataset\n",
        "print(Clothesdata_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary statistics for numerical columns in the dataset\n",
        "Clothesdata_df.describe()"
      ],
      "metadata": {
        "id": "9QkFg5mKlsmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows and columns in the dataset\n",
        "row_no, col_no = Clothesdata_df.shape\n",
        "print(f\"The shape of the dataset is {row_no} reviews with {col_no} columns.\")"
      ],
      "metadata": {
        "id": "AN2FxQAXl5uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the count of missing values in each column\n",
        "Clothesdata_df.isna().sum()"
      ],
      "metadata": {
        "id": "tOYdZj-wmAD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the data types and non-null counts for each column\n",
        "Clothesdata_df.info()"
      ],
      "metadata": {
        "id": "4QO8wR2ymD_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the columns that are not useful for the analysis\n",
        "cols_to_drop = ['Id', 'Clothing ID', 'Title', 'Department Name', 'Class Name']\n",
        "# Remove the specified columns from the dataset\n",
        "Clothesdata_df = Clothesdata_df.drop(columns=cols_to_drop, errors='ignore')"
      ],
      "metadata": {
        "id": "BCA-a9Ovy9RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where 'Review Text' is either missing or an empty string\n",
        "Cloths_Df_PP = Clothesdata_df[Clothesdata_df['Review Text'].notna() & (Clothesdata_df['Review Text'] != '')]\n",
        "# Drop rows that have null values in the 'Division Name' column\n",
        "Cloths_Df_PP = Cloths_Df_PP.dropna(subset=['Division Name'])"
      ],
      "metadata": {
        "id": "cTzwujcdzEoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows and columns after removing missing values\n",
        "row_pp, col_pp = Cloths_Df_PP.shape\n",
        "print(f\"The shape of the dataset after pre-processing is {row_pp} reviews with {col_pp} columns.\")"
      ],
      "metadata": {
        "id": "Ml0GwAs8zGE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in each column after data cleaning\n",
        "Cloths_Df_PP.isna().sum()"
      ],
      "metadata": {
        "id": "hzYE1nnuzHaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary resources from NLTK for stopwords and lemmatization\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# Create a lemmatizer instance\n",
        "lemmatizer_tool = WordNetLemmatizer()\n",
        "# Load the set of English stopwords\n",
        "stopword_list = set(stopwords.words('english'))\n",
        "# Function to clean and standardize review text\n",
        "def clean_review_text(input_text):\n",
        "    \"\"\"\n",
        "    Cleans the input review by applying a sequence of text preprocessing steps:\n",
        "    - Converts all characters to lowercase\n",
        "    - Removes numbers and punctuation\n",
        "    - Splits text into individual words (tokens)\n",
        "    - Filters out common stopwords\n",
        "    - Lemmatizes words to their root form\n",
        "    - Reassembles the cleaned words into a single string\n",
        "\n",
        "    Args:\n",
        "        input_text (str): Raw review text to be processed\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned and processed review text\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    lower_text = input_text.lower()\n",
        "    # Remove punctuation and digits\n",
        "    stripped_text = re.sub(r'[^a-z\\s]', '', lower_text)\n",
        "    # Split into tokens\n",
        "    token_list = stripped_text.split()\n",
        "    # Remove stopwords and apply lemmatization\n",
        "    processed_tokens = [lemmatizer_tool.lemmatize(token) for token in token_list if token not in stopword_list]\n",
        "    # Rejoin tokens into a string\n",
        "    return ' '.join(processed_tokens)\n",
        "# Apply the text cleaning function to the 'Review Text' column\n",
        "Cloths_Df_PP['Cloth_rev_PP'] = Cloths_Df_PP['Review Text'].apply(clean_review_text)\n",
        "# Display the original and cleaned review text side by side\n",
        "Cloths_Df_PP[['Review Text', 'Cloth_rev_PP']]"
      ],
      "metadata": {
        "id": "i-6AsTwRzH9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify sentiment based on the numeric rating\n",
        "def map_rating_to_sentiment(rating):\n",
        "    \"\"\"\n",
        "    Maps a numerical rating to a sentiment label.\n",
        "\n",
        "    Args:\n",
        "        rating (int or float): The review rating value\n",
        "\n",
        "    Returns:\n",
        "        str: Sentiment label based on rating:\n",
        "             - 'Positive' for rating above 3\n",
        "             - 'Neutral' for rating equal to 3\n",
        "             - 'Negative' for rating below 3\n",
        "    \"\"\"\n",
        "    if rating > 3:\n",
        "        return \"Positive\"\n",
        "    elif rating == 3:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Negative\"\n",
        "# Apply the sentiment mapping function to create a new column\n",
        "Cloths_Df_PP['Sentiment'] = Cloths_Df_PP['Rating'].apply(map_rating_to_sentiment)"
      ],
      "metadata": {
        "id": "Wdo8nHwQzKbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column that stores the number of characters in each review\n",
        "Cloths_Df_PP['review_length'] = Cloths_Df_PP['Review Text'].apply(len)"
      ],
      "metadata": {
        "id": "U03sjTOxzL-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify and eliminate duplicate records from the dataset\n",
        "print(f\"Number of duplicate rows before removal: {Cloths_Df_PP.duplicated().sum()}\")\n",
        "Cloths_Df_PP = Cloths_Df_PP.drop_duplicates()\n",
        "print(f\"Number of duplicate rows after removal: {Cloths_Df_PP.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "C7b8nbI-zMnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first five entries of the cleaned dataset\n",
        "Cloths_Df_PP.head()"
      ],
      "metadata": {
        "id": "B9TTmmmfzOqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display column data types and non-null counts after preprocessing\n",
        "print(Cloths_Df_PP.info())"
      ],
      "metadata": {
        "id": "2ThCgk_bzQsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all column names in the dataset after preprocessing\n",
        "Cloths_Df_PP.columns"
      ],
      "metadata": {
        "id": "pkgyYAbSzSh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar chart to visualize the distribution of sentiment labels\n",
        "Cloths_Df_PP['Sentiment'].value_counts().plot(kind='bar',\n",
        "                                              color=['green', 'orange', 'red'])\n",
        "# Set the chart title and axis labels\n",
        "plt.title('Distribution of Sentiment Classes')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Reviews')\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kcytdnn7zTGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the column that holds character count of reviews\n",
        "Cloths_Df_PP['char_count_review'] = Cloths_Df_PP['Review Text'].apply(len)\n",
        "# Create a histogram to visualize how review lengths are distributed\n",
        "Cloths_Df_PP['char_count_review'].hist(bins='rice', color='lightgreen')\n",
        "# Set the title and axis labels for the plot\n",
        "plt.title('Distribution of Review Length')\n",
        "plt.xlabel('Review Length (Character Count)')\n",
        "plt.ylabel('Frequency')\n",
        "# Display the histogram\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VEKbLY1yzUhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the numeric fields to include in the correlation heatmap\n",
        "num_fields_corr = ['Rating', 'char_count_review']\n",
        "# Calculate correlation values between the selected numeric columns\n",
        "corr_values_matrix = Cloths_Df_PP[num_fields_corr].corr()\n",
        "# Plot a heatmap to visualize the correlation matrix\n",
        "sns.heatmap(corr_values_matrix, annot=True, cmap='Blues')\n",
        "# Set the heatmap title\n",
        "plt.title('Correlation Heatmap of Rating and Review Length')\n",
        "# Display the heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ST6EyFFQzXi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate records by sentiment category\n",
        "positive_reviews = Cloths_Df_PP[Cloths_Df_PP['Sentiment'] == 'Positive']\n",
        "neutral_reviews = Cloths_Df_PP[Cloths_Df_PP['Sentiment'] == 'Neutral']\n",
        "negative_reviews = Cloths_Df_PP[Cloths_Df_PP['Sentiment'] == 'Negative']\n",
        "# Determine the count of the majority class\n",
        "max_class_count = positive_reviews.shape[0]\n",
        "# Upsample minority classes to match the majority class size\n",
        "neutral_upsampled = resample(neutral_reviews, replace=True,\n",
        "                             n_samples=max_class_count,random_state=7890)\n",
        "\n",
        "negative_upsampled = resample(negative_reviews,replace=True,\n",
        "                              n_samples=max_class_count,random_state=7890)\n",
        "# Combine all classes into a balanced dataset\n",
        "Cloths_Df_Balanced = pd.concat([positive_reviews, neutral_upsampled, negative_upsampled])\n",
        "# Shuffle the rows to randomize class distribution\n",
        "Cloths_Df_Balanced = Cloths_Df_Balanced.sample(frac=1, random_state=7890).reset_index(drop=True)\n",
        "# Display the class distribution after balancing\n",
        "print(\"Balanced Sentiment Class Distribution:\")\n",
        "print(Cloths_Df_Balanced['Sentiment'].value_counts())"
      ],
      "metadata": {
        "id": "m-l84xPQzY5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the balanced dataset into training and testing sets\n",
        "Cloths_Df_Train, Cloths_Df_Test, cloths_df_Sen, cloths_df_Sen_Test = train_test_split(\n",
        "    Cloths_Df_Balanced['Cloth_rev_PP'],Cloths_Df_Balanced['Sentiment'],\n",
        "    test_size=0.2,random_state=7890,stratify=Cloths_Df_Balanced['Sentiment'],)\n",
        "# Convert target labels to categorical type for model compatibility\n",
        "cloths_df_Sen = cloths_df_Sen.astype('category')\n",
        "cloths_df_Sen_Test = cloths_df_Sen_Test.astype('category')"
      ],
      "metadata": {
        "id": "qbiNMAhDzaPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained BERT tokenizer\n",
        "Cloths_Tknzr = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# Tokenize and encode the training and testing text data\n",
        "cloths_train_encoded = Cloths_Tknzr(Cloths_Df_Train.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "cloths_test_encoded = Cloths_Tknzr(Cloths_Df_Test.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "# Convert sentiment labels to numeric format\n",
        "cloths_train_labels = torch.tensor(cloths_df_Sen.cat.codes.values)\n",
        "cloths_test_labels = torch.tensor(cloths_df_Sen_Test.cat.codes.values)\n",
        "# Construct TensorDatasets for model training and evaluation\n",
        "cloths_train_dataset = TensorDataset(cloths_train_encoded['input_ids'],\n",
        "                                     cloths_train_encoded['attention_mask'],\n",
        "                                     cloths_train_labels)\n",
        "cloths_test_dataset = TensorDataset(cloths_test_encoded['input_ids'],\n",
        "                                    cloths_test_encoded['attention_mask'],\n",
        "                                    cloths_test_labels)\n",
        "# Encode sentiment labels into numeric codes and store in a new column\n",
        "Cloths_Df_Balanced['Sentiment'] = Cloths_Df_Balanced['Sentiment'].astype('category')\n",
        "Cloths_Df_Balanced['label'] = Cloths_Df_Balanced['Sentiment'].cat.codes\n",
        "cloths_label_names = Cloths_Df_Balanced['Sentiment'].cat.categories.tolist()\n",
        "# Display the sentiment label mapping\n",
        "print(\"Label mapping:\", dict(enumerate(cloths_label_names)))"
      ],
      "metadata": {
        "id": "kebDmzIuzbq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model for sequence classification with the appropriate number of sentiment labels\n",
        "cloths_sentiment_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=len(cloths_label_names)).to(device)\n",
        "# Define optimizer and loss function for model training\n",
        "cloths_bert_optimizer = AdamW(cloths_sentiment_model.parameters(), lr=1e-5)\n",
        "cloths_bert_loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "hj0ZBiA-zdE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for training and testing\n",
        "cloths_train_loader = DataLoader(cloths_train_dataset, batch_size=8, shuffle=True)\n",
        "cloths_test_loader = DataLoader(cloths_test_dataset, batch_size=8)\n",
        "# Initialize lists to store accuracy and loss metrics across epochs\n",
        "cloths_train_accuracies = []\n",
        "cloths_test_accuracies = []\n",
        "cloths_epoch_losses = []\n",
        "# Start the training loop for a defined number of epochs\n",
        "for epoch in range(10):\n",
        "    # Set the model to training mode\n",
        "    cloths_sentiment_model.train()\n",
        "    # Reset tracking variables for each epoch\n",
        "    cloths_epoch_train_loss = 0\n",
        "    cloths_epoch_train_correct = 0\n",
        "    cloths_epoch_train_total = 0\n",
        "    # Iterate over training batches\n",
        "    for batch in tqdm(cloths_train_loader, desc=f\"Epoch {epoch+1} - Training\"):\n",
        "        cloths_input_ids, cloths_attention_mask, cloths_batch_labels = [b.to(device) for b in batch]\n",
        "        cloths_batch_labels = cloths_batch_labels.long()\n",
        "        # Clear previous gradients\n",
        "        cloths_bert_optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        btch_op = cloths_sentiment_model(input_ids=cloths_input_ids, attention_mask=cloths_attention_mask)\n",
        "        # Compute loss\n",
        "        btch_loss = cloths_bert_loss_fn(btch_op.logits, cloths_batch_labels)\n",
        "        # Backward pass and optimization step\n",
        "        btch_loss.backward()\n",
        "        cloths_bert_optimizer.step()\n",
        "        # Accumulate total loss for the epoch\n",
        "        cloths_epoch_train_loss += btch_loss.item()\n",
        "\n",
        "        # Calculate correct predictions for training accuracy\n",
        "        cloths_batch_preds = torch.argmax(btch_op.logits, dim=1)\n",
        "        cloths_epoch_train_correct += (cloths_batch_preds == cloths_batch_labels).sum().item()\n",
        "        cloths_epoch_train_total += cloths_batch_labels.size(0)\n",
        "\n",
        "    # Compute and store training accuracy and average loss for the epoch\n",
        "    epoch_train_acc = cloths_epoch_train_correct / cloths_epoch_train_total\n",
        "    cloths_train_accuracies.append(epoch_train_acc)\n",
        "    cloths_epoch_losses.append(cloths_epoch_train_loss / len(cloths_train_loader))\n",
        "    # Set the model to evaluation mode for testing\n",
        "    cloths_sentiment_model.eval()\n",
        "    cloths_epoch_test_correct = 0\n",
        "    cloths_epoch_test_total = 0\n",
        "    # Evaluate on the test set without gradient calculation\n",
        "    with torch.no_grad():\n",
        "        for batch in cloths_test_loader:\n",
        "            cloths_input_ids, cloths_attention_mask, cloths_batch_labels = [b.to(device) for b in batch]\n",
        "            cloths_batch_labels = cloths_batch_labels.long()\n",
        "            torch_op = cloths_sentiment_model(input_ids=cloths_input_ids, attention_mask=cloths_attention_mask)\n",
        "            cloths_batch_preds = torch.argmax(torch_op.logits, dim=1)\n",
        "            cloths_epoch_test_correct += (cloths_batch_preds == cloths_batch_labels).sum().item()\n",
        "            cloths_epoch_test_total += cloths_batch_labels.size(0)\n",
        "    # Compute and store test accuracy for the epoch\n",
        "    epoch_test_acc = cloths_epoch_test_correct / cloths_epoch_test_total\n",
        "    cloths_test_accuracies.append(epoch_test_acc)\n",
        "    # Print training and testing metrics for the current epoch\n",
        "    print(f\"Epoch {epoch+1}: Train Acc = {epoch_train_acc:.4f}, Test Acc = {epoch_test_acc:.4f}, Loss = {cloths_epoch_train_loss / len(cloths_train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "BnR6-STPzega"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of epoch numbers for plotting\n",
        "cloths_epoch_list = list(range(1, len(cloths_train_accuracies) + 1))\n",
        "# Plot training and testing accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(cloths_epoch_list, cloths_train_accuracies, marker='o', label='Training Accuracy')\n",
        "plt.plot(cloths_epoch_list, cloths_test_accuracies, marker='o', label='Testing Accuracy')\n",
        "# Set plot titles and axis labels\n",
        "plt.title(\"Training vs Testing Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xticks(cloths_epoch_list)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eCyKy4n_zgHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "cloths_sentiment_model.eval()\n",
        "# Create a DataLoader for the test dataset\n",
        "cloths_test_loader = DataLoader(cloths_test_dataset, batch_size=8)\n",
        "# Lists to store predicted and actual sentiment labels\n",
        "cloths_final_preds = []\n",
        "cloths_final_true = []\n",
        "# Run inference without gradient computation\n",
        "with torch.no_grad():\n",
        "    for batch in cloths_test_loader:\n",
        "        cloths_input_ids, cloths_attention_mask, cloths_batch_labels = [b.to(device) for b in batch]\n",
        "        cloths_outputs = cloths_sentiment_model(input_ids=cloths_input_ids, attention_mask=cloths_attention_mask)\n",
        "        cloths_preds = torch.argmax(cloths_outputs.logits, dim=1)\n",
        "        cloths_final_preds.extend(cloths_preds.cpu().numpy())\n",
        "        cloths_final_true.extend(cloths_batch_labels.cpu().numpy())\n",
        "# Calculate and print accuracy and classification report\n",
        "cloths_test_acc = accuracy_score(cloths_final_true, cloths_final_preds)\n",
        "print(f\"Test Accuracy: {cloths_test_acc:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(cloths_final_true, cloths_final_preds, target_names=cloths_label_names))"
      ],
      "metadata": {
        "id": "52A3Bg5Czhni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix using the final predictions and true labels\n",
        "cloths_conf_matrix = confusion_matrix(cloths_final_true, cloths_final_preds)\n",
        "cloths_cm_display = ConfusionMatrixDisplay(confusion_matrix=cloths_conf_matrix, display_labels=cloths_label_names)\n",
        "cloths_cm_display.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix for Sentiment Prediction\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NnxVOXr1zjEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 5 random samples from the test set for comparison\n",
        "cloths_sample_indices = np.random.choice(len(Cloths_Df_Test), 5, replace=False)\n",
        "# Convert test labels to category codes\n",
        "cloths_df_Sen_Test_cat = cloths_df_Sen_Test.cat.codes\n",
        "# Loop through each selected sample and compare predictions\n",
        "for idx in cloths_sample_indices:\n",
        "    cloths_sample_text = Cloths_Df_Test.iloc[idx]\n",
        "    true_label_code = cloths_df_Sen_Test_cat.iloc[idx]\n",
        "    true_label = cloths_label_names[true_label_code]\n",
        "    # Tokenize the review text for inference\n",
        "    cloths_sample_inputs = Cloths_Tknzr(cloths_sample_text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "    # Predict sentiment using the trained model\n",
        "    with torch.no_grad():\n",
        "        cloths_sample_outputs = cloths_sentiment_model(**cloths_sample_inputs)\n",
        "    cloths_predicted_label = cloths_label_names[torch.argmax(cloths_sample_outputs.logits, dim=1).item()]\n",
        "    # Print the review, true label, and predicted label\n",
        "    print(\"\\nReview Text:\", cloths_sample_text)\n",
        "    print(\"Actual Sentiment   :\", true_label)\n",
        "    print(\"Predicted Sentiment:\", cloths_predicted_label)"
      ],
      "metadata": {
        "id": "QyT305urzmmP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}